{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Convert training script to use horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to make the following modifications to your training script to use horovod for distributed training.\n",
    "\n",
    "1. Run hvd.init()\n",
    "2. Pin a server GPU to be used by this process using config.gpu_options.visible_device_list.\n",
    "3. Scale the learning rate by the number of workers.\n",
    "4. Wrap the optimizer in hvd.DistributedOptimizer.\n",
    "5. Add hvd.callbacks.BroadcastGlobalVariablesCallback(0) to broadcast initial variable states from rank 0 to all other processes.\n",
    "6. Modify your code to save checkpoints only on worker 0 to prevent other workers from corrupting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for cells that say **Change X** and fill in those cells with the modifications - where **X** is the change number. There are a total of 8 changes.\n",
    "Click on **Solution** to see the answers\n",
    "\n",
    "After you've finished making necessary changes, run the script by hitting *Run > Run All Cells*.\n",
    "\n",
    "**Confirm that that the script still runs after introducing the horovod API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change 1: Import horovod and keras backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Solution</b></summary>\n",
    "   <pre>\n",
    "import horovod.tensorflow.keras as hvd\n",
    "import tensorflow.keras.backend as K\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from model_def import get_model\n",
    "    \n",
    "HEIGHT = 32\n",
    "WIDTH  = 32\n",
    "DEPTH  = 3\n",
    "NUM_CLASSES = 10\n",
    "NUM_TRAIN_IMAGES = 40000\n",
    "NUM_VALID_IMAGES = 10000\n",
    "NUM_TEST_IMAGES  = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocess_fn(image):\n",
    "\n",
    "    # Resize the image to add four extra pixels on each side.\n",
    "    image = tf.image.resize_image_with_crop_or_pad(image, HEIGHT + 8, WIDTH + 8)\n",
    "\n",
    "    # Randomly crop a [HEIGHT, WIDTH] section of the image.\n",
    "    image = tf.random_crop(image, [HEIGHT, WIDTH, DEPTH])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(filenames, batch_size):\n",
    "    \"\"\"Read the images and labels from 'filenames'.\"\"\"\n",
    "    # Repeat infinitely.\n",
    "    dataset = tf.data.TFRecordDataset(filenames).repeat()\n",
    "\n",
    "    # Parse records.\n",
    "    dataset = dataset.map(single_example_parser, num_parallel_calls=1)\n",
    "\n",
    "    # Batch it up.\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    image_batch, label_batch = iterator.get_next()\n",
    "    return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_example_parser(serialized_example):\n",
    "    \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "    # Dimensions of the images in the CIFAR-10 dataset.\n",
    "    # See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the\n",
    "    # input format.\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)\n",
    "    image.set_shape([DEPTH * HEIGHT * WIDTH])\n",
    "\n",
    "    # Reshape from [depth * height * width] to [depth, height, width].\n",
    "    image = tf.cast(\n",
    "        tf.transpose(tf.reshape(image, [DEPTH, HEIGHT, WIDTH]), [1, 2, 0]),\n",
    "        tf.float32)\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    \n",
    "    image = train_preprocess_fn(image)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "epochs = 1\n",
    "lr = 0.01\n",
    "batch_size = 128\n",
    "momentum = 0.9\n",
    "weight_decay = 2e-4\n",
    "optimizer = 'sgd'\n",
    "gpu_count = 1\n",
    "\n",
    "# Data directories and other options\n",
    "checkpoint_dir = '../ckpt_dir'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "train_dir = '../data/train'\n",
    "validation_dir = '../data/validation'\n",
    "eval_dir = '../data/eval'\n",
    "\n",
    "train_dataset = make_batch(train_dir+'/train.tfrecords',  batch_size)\n",
    "val_dataset = make_batch(validation_dir+'/validation.tfrecords', batch_size)\n",
    "eval_dataset = make_batch(eval_dir+'/eval.tfrecords', batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change 2: Initialize horovod and get the size of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Solution</b></summary>\n",
    "   <pre>\n",
    "hvd.init()\n",
    "size = hvd.size()\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change 3 - Pin GPU to be used to process local rank (one GPU per process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Solution</b></summary>\n",
    "   <pre>\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "K.set_session(tf.Session(config=config))\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(lr, weight_decay, optimizer, momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change 4: How will you update the learning rate for distributed training? What changes should you make to the following command?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=lr, decay=weight_decay, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Solution</b></summary>\n",
    "   <pre>\n",
    "opt = SGD(lr=lr * size, decay=weight_decay, momentum=momentum)\n",
    "\n",
    "You need to scale the learning using the size of the cluster (total number of workers)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change 6: How will you convert the optimizer to distributed optimizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Solution</b></summary>\n",
    "   <pre>\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change 7: Add callbacks for syncing initial state, and saving checkpoints only on 1st worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Solution</b></summary>\n",
    "   <pre>\n",
    "callbacks = []\n",
    "callbacks.append(hvd.callbacks.BroadcastGlobalVariablesCallback(0))\n",
    "callbacks.append(hvd.callbacks.MetricAverageCallback())\n",
    "callbacks.append(hvd.callbacks.LearningRateWarmupCallback(warmup_epochs=5, verbose=1))\n",
    "callbacks.append(tf.keras.callbacks.ReduceLROnPlateau(patience=10, verbose=1))\n",
    "if hvd.rank() == 0:\n",
    "    callbacks.append(ModelCheckpoint('ckpt_dir' + '/checkpoint-{epoch}.h5'))\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change 8: Update the number of steps/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model\n",
    "history = model.fit(x=train_dataset[0], y=train_dataset[1],\n",
    "                    steps_per_epoch=NUM_TRAIN_IMAGES // batch_size,\n",
    "                    validation_data=val_dataset,\n",
    "                    validation_steps=NUM_VALID_IMAGES // batch_size,\n",
    "                    epochs=epochs, \n",
    "                    callbacks=[ModelCheckpoint(checkpoint_dir + '/checkpoint-{epoch}.h5')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><b>Solution</b></summary>\n",
    "   <pre>\n",
    "history = model.fit(x=train_dataset[0], y=train_dataset[1],\n",
    "                    steps_per_epoch= (NUM_TRAIN_IMAGES // batch_size)// size,\n",
    "                    validation_data=val_dataset,\n",
    "                    validation_steps= (NUM_VALID_IMAGES // batch_size)// size,\n",
    "                    epochs=epochs, callbacks=callbacks)\n",
    "</pre>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "score = model.evaluate(eval_dataset[0],\n",
    "                       eval_dataset[1],\n",
    "                       steps=NUM_TEST_IMAGES // batch_size,\n",
    "                       verbose=0)\n",
    "print('Test loss    :', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note once these changes are made, you can convert the jupyter notebook into a python training script by running:\n",
    "<code> $ jupyter nbconvert --to script notebook_name.ipynb </code>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
